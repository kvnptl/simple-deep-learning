{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segmentation with U-Net\n",
    "- Dataset: MNIST Extended\n",
    "- Reference: https://github.com/LukeTonin/simple-deep-learning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchinfo import summary\n",
    "import cv2\n",
    "from typing import List, Tuple\n",
    "from PIL import Image\n",
    "import imutils\n",
    "from pathlib import Path\n",
    "import pprint\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchmetrics\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets, models\n",
    "\n",
    "import config\n",
    "import dataset_generation\n",
    "import utils\n",
    "\n",
    "import importlib\n",
    "importlib.reload(dataset_generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORKERS = config.NUM_WORKERS\n",
    "BATCH_SIZE = config.BATCH_SIZE\n",
    "PIN_MEMORY = config.PIN_MEMORY\n",
    "\n",
    "TOTAL_SAMPLES = config.TOTAL_SAMPLES\n",
    "num_classes = config.NUM_CLASSES\n",
    "\n",
    "EPOCHS = config.EPOCHS\n",
    "LR_RATE = config.LR_RATE\n",
    "\n",
    "TRAIN_VAL_SPLIT = config.TRAIN_VAL_SPLIT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet architecture\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img src=\"https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png\" width=45% />\n",
    "</p>\n",
    "\n",
    "Reference: https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the block\n",
    "encoder_block = Block(1, 64)\n",
    "x = torch.rand(1, 1, 60, 60)\n",
    "print(f'Shape of the encoder block: {encoder_block(x).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels=(1, 64, 128, 256)): # 512\n",
    "        super().__init__()\n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "            [Block(channels[i], channels[i + 1]) for i in range(len(channels) - 1)]\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        block_outputs = []\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x)\n",
    "            block_outputs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return block_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the encoder\n",
    "encoder = Encoder()\n",
    "x = torch.rand(1, 1, 60, 60)\n",
    "encoder_outputs = encoder(x)\n",
    "\n",
    "for op in encoder_outputs:\n",
    "    print(f'Shape of the encoder output: {op.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels=(256, 128, 64)): #512\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.decoder_blocks = nn.ModuleList(\n",
    "            [Block(channels[i], channels[i + 1]) for i in range(len(channels) - 1)]\n",
    "        )\n",
    "        self.upconvolution = nn.ModuleList(\n",
    "            [nn.ConvTranspose2d(channels[i], channels[i + 1], kernel_size=2, stride=2) for i in range(len(channels) - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, encoder_outputs):\n",
    "        for i in range(len(self.channels) - 1):\n",
    "            x = self.upconvolution[i](x)\n",
    "            encoder_output = self.crop(encoder_outputs[i], x)\n",
    "            x = torch.cat([x, encoder_output], dim=1)\n",
    "            x = self.decoder_blocks[i](x)\n",
    "        return x\n",
    "\n",
    "    # Following the paper, we crop the encoder output to match the shape of decoder output    \n",
    "    def crop(self, encoder_output, tensor):\n",
    "        _, _, H, W = tensor.shape\n",
    "        encoder_output = torchvision.transforms.CenterCrop([H, W])(encoder_output)\n",
    "        return encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the decoder\n",
    "decoder = Decoder()\n",
    "x = torch.rand(1, 256, 7, 7)\n",
    "decoder(x, encoder_outputs[::-1][1:]) # Pass the encoder outputs in reverse order\n",
    "print(f'Shape of the decoder output: {decoder(x, encoder_outputs[::-1][1:]).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, encoder_channels=(1, 64, 128, 256), decoder_channels=(256, 128, 64), num_classes=5, retain_dim=False, output_size=(60, 60)):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(encoder_channels)\n",
    "        self.decoder = Decoder(decoder_channels)\n",
    "        self.head = nn.Conv2d(decoder_channels[-1], num_classes, kernel_size=1)\n",
    "        self.retain_dim = retain_dim\n",
    "        self.output_size = output_size\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_outputs = self.encoder(x)\n",
    "        out = self.decoder(encoder_outputs[-1], encoder_outputs[::-1][1:])\n",
    "        out = self.head(out)\n",
    "        if self.retain_dim:\n",
    "            out = nn.functional.interpolate(out, self.output_size)\n",
    "        # Apply sigmoid activation\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the model\n",
    "model = UNet(retain_dim=True)\n",
    "x = torch.rand(1, 1, 60, 60)\n",
    "out = model(x)\n",
    "print(f'Shape of the model output: {out.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTExtendedDataset(Dataset):\n",
    "  def __init__(self, count, transform=None):\n",
    "    \n",
    "    self.input_images, self.target_masks, _, _ = dataset_generation.mnist_extended_dataset(total_train_samples=count, total_test_samples=1, num_classes=num_classes)\n",
    "\n",
    "    # permute target mask \n",
    "    self.target_masks = np.transpose(self.target_masks, (0, 3, 1, 2))\n",
    "\n",
    "    # Convert to datatype float32\n",
    "    self.input_images = self.input_images.astype(np.float32)\n",
    "    self.target_masks = self.target_masks.astype(np.float32)\n",
    "\n",
    "    self.transform = transform\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.input_images)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    image = self.input_images[idx]\n",
    "    mask = self.target_masks[idx]\n",
    "    if self.transform:\n",
    "      image = self.transform(image)\n",
    "\n",
    "    return [image, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "trans = transforms.Compose([\n",
    "  transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_size = int(TRAIN_VAL_SPLIT * TOTAL_SAMPLES)\n",
    "val_size = int((1 - TRAIN_VAL_SPLIT) * TOTAL_SAMPLES)\n",
    "\n",
    "train_data = MNISTExtendedDataset(count=train_size, transform=trans)\n",
    "val_data = MNISTExtendedDataset(count=val_size, transform=trans)\n",
    "test_data = MNISTExtendedDataset(count=val_size, transform=trans)\n",
    "\n",
    "print(f'Shape of train_data: {len(train_data)}')\n",
    "print(f'Shape of val_data: {len(val_data)}')\n",
    "print(f'Shape of test_data: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(dataset=train_data, \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=True, \n",
    "                          num_workers=NUM_WORKERS, \n",
    "                          pin_memory=PIN_MEMORY)\n",
    "\n",
    "val_loader = DataLoader(dataset=val_data,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        pin_memory=PIN_MEMORY)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_data, \n",
    "                         batch_size=1, \n",
    "                         shuffle=False, \n",
    "                         num_workers=NUM_WORKERS, \n",
    "                         pin_memory=PIN_MEMORY)\n",
    "\n",
    "print(f'Number of train batches: {len(train_loader)}')\n",
    "print(f'Number of val batches: {len(val_loader)}')\n",
    "print(f'Number of test batches: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a train input and output pair\n",
    "i = np.random.randint(0, len(train_loader.dataset))\n",
    "train_x_sample, train_y_sample = next(iter(train_loader))\n",
    "print(f'Shape of train_x_sample: {train_x_sample.shape}')\n",
    "print(f'Shape of train_y_sample: {train_y_sample.shape}')\n",
    "\n",
    "# get min and max of train y\n",
    "train_y_min, train_y_max = train_y_sample.min(), train_y_sample.max()\n",
    "print(f'Min and max of train_y_sample: {train_y_min}, {train_y_max}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_sample.dtype, train_y_sample.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "random_indices = np.random.choice(len(train_loader.dataset), size=6, replace=False)\n",
    "\n",
    "fig, axs = plt.subplots(3, 2, figsize=(5, 5))  # Adjust the figure size as needed\n",
    "\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    idx = random_indices[i // 2]\n",
    "    data = train_loader.dataset[idx]\n",
    "\n",
    "    # Just to put in order in the plot\n",
    "    if i % 2 == 0:\n",
    "        image = data[0]\n",
    "        image = image.permute(1, 2, 0)\n",
    "        ax.imshow(image, cmap=plt.cm.binary)  \n",
    "        ax.set_title(\"Original Image\")\n",
    "    else:\n",
    "        segmentation = data[1]  \n",
    "        segmentation = np.transpose(segmentation, (1, 2, 0))\n",
    "        seg_img = dataset_generation.display_segmented_image(segmentation)\n",
    "        ax.imshow(seg_img, cmap=plt.cm.binary)\n",
    "        ax.set_title(\"Segmented Image\")\n",
    "\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "fig.suptitle('Input and Segmented Images', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_model = UNet(retain_dim=True, num_classes=num_classes, output_size=(60, 60)).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "summary(model=unet_model,\n",
    "        input_size=(1, 1, 60, 60),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        depth=5\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(unet_model.parameters(), lr=LR_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.set_seed()\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "start_time = timer()\n",
    "\n",
    "# Store train and validation losses\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    unet_model.train()\n",
    "\n",
    "    train_loss = 0.0\n",
    "    val_loss = 0.0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        pred_logits = unet_model(x)\n",
    "        loss = loss_fn(pred_logits, y)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    unet_model.eval()\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x = x.to(DEVICE)\n",
    "            y = y.to(DEVICE)\n",
    "\n",
    "            pred_logits = unet_model(x)\n",
    "            loss = loss_fn(pred_logits, y)\n",
    "\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{EPOCHS} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f}')\n",
    "\n",
    "end_time = timer()\n",
    "total_time = end_time - start_time\n",
    "print(f\"Total training time: {total_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot train and validation loss over epochs\n",
    "plt.plot(train_losses, label='train')\n",
    "plt.plot(val_losses, label='val')\n",
    "plt.legend()\n",
    "plt.title('Loss over epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate mean IoU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(preds, labels):\n",
    "    # Ensure the input tensors are binary (0 or 1)\n",
    "    # preds and labels should be of shape [batch_size, n_classes, height, width]\n",
    "    smooth = 1e-6  # Small epsilon to avoid division by zero\n",
    "\n",
    "    # True Positives (TP)\n",
    "    intersection = torch.logical_and(preds, labels).float().sum((2, 3))\n",
    "\n",
    "    # False Positives (FP)\n",
    "    false_positive = torch.logical_and(preds, torch.logical_not(labels)).float().sum((2, 3))\n",
    "\n",
    "    # False Negatives (FN)\n",
    "    false_negative = torch.logical_and(torch.logical_not(preds), labels).float().sum((2, 3))\n",
    "\n",
    "    # Union is calculated as TP + FP + FN\n",
    "    union = intersection + false_positive + false_negative\n",
    "\n",
    "    # IoU for each class\n",
    "    IoU = (intersection + smooth) / (union + smooth)\n",
    "\n",
    "    return IoU\n",
    "\n",
    "def mean_iou(preds, labels):\n",
    "    # Calculate IoU for each class\n",
    "    ious = calculate_iou(preds, labels)\n",
    "    # Mean IoU across all classes\n",
    "    return ious.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_predictions(orig_img, gt_img, pred_img):\n",
    "    plt.clf()\n",
    "    plt.figure(figsize=(18, 6))  \n",
    "\n",
    "    # Plot the original image\n",
    "    ax1 = plt.subplot(1, 3, 1)  # 1 row, 3 columns, 1st subplot\n",
    "    image = orig_img.permute(1, 2, 0).numpy()  \n",
    "    ax1.imshow(image, cmap=plt.cm.binary)\n",
    "    ax1.set_title(\"Original Image\")\n",
    "    ax1.axis('off')  \n",
    "\n",
    "    # Plot the ground truth image\n",
    "    ax2 = plt.subplot(1, 3, 2)  # 1 row, 3 columns, 2nd subplot\n",
    "    gt_segmentation = gt_img.permute(1, 2, 0).numpy() \n",
    "    gt_seg_img = dataset_generation.display_segmented_image(gt_segmentation)  \n",
    "    ax2.imshow(gt_seg_img)\n",
    "    ax2.set_title(\"Ground Truth Image\")\n",
    "    ax2.axis('off')  # Hide the axis\n",
    "\n",
    "    # Plot the predicted image\n",
    "    ax3 = plt.subplot(1, 3, 3)  # 1 row, 3 columns, 3rd subplot\n",
    "    pred_segmentation = pred_img.permute(1, 2, 0).numpy()\n",
    "    pred_seg_img = dataset_generation.display_segmented_image(pred_segmentation, threshold=0.5)\n",
    "    ax3.imshow(pred_seg_img)\n",
    "    ax3.set_title(\"Predicted Image\")\n",
    "    ax3.axis('off')  # Hide the axis\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def min_max_normalize(x, xmin, xmax):\n",
    "    return (x - xmin) / (xmax - xmin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "unet_model.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    for idx, (x, y) in enumerate(train_loader):\n",
    "        x = x.to(DEVICE)\n",
    "        y = y.to(DEVICE)\n",
    "\n",
    "        pred_logits = unet_model(x)\n",
    "\n",
    "        pred_norm = min_max_normalize(pred_logits, pred_logits.min(), pred_logits.max())\n",
    "\n",
    "        # Min and max of train y\n",
    "        print(f'Min and max of y: {y.min()}, {y.max()}')\n",
    "        print(f'Min and max of pred: {pred_logits.min()}, {pred_logits.max()}')\n",
    "        print(f'Min and max of pred: {pred_norm.min()}, {pred_norm.max()}')\n",
    "\n",
    "        pred_softmax = torch.softmax(pred_logits, dim=1)\n",
    "        pred_argmax = torch.argmax(pred_softmax, dim=1).unsqueeze(1)\n",
    "\n",
    "        print(f'Pred argmax shape: {pred_argmax.shape}')\n",
    "\n",
    "        iou_scores = calculate_iou(pred_logits, y)\n",
    "        # mean_iou_score = mean_iou(pred_logits, y)\n",
    "\n",
    "        print(f\"Mean IoU: {iou_scores.cpu().numpy().mean()}\")\n",
    "\n",
    "        visualize_predictions(x[0].cpu(), y[0].cpu(), pred_norm[0].cpu())\n",
    "        break\n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
