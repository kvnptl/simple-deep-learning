{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, 3) \n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the encoder block: torch.Size([1, 64, 568, 568])\n"
     ]
    }
   ],
   "source": [
    "# Check the block\n",
    "encoder_block = Block(1, 64)\n",
    "x = torch.rand(1, 1, 572, 572)\n",
    "print(f'Shape of the encoder block: {encoder_block(x).shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, channels=(1, 64, 128, 256, 512, 1024)):\n",
    "        super().__init__()\n",
    "        self.encoder_blocks = nn.ModuleList(\n",
    "            [Block(channels[i], channels[i + 1]) for i in range(len(channels) - 1)]\n",
    "        )\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        block_outputs = []\n",
    "        for block in self.encoder_blocks:\n",
    "            x = block(x)\n",
    "            block_outputs.append(x)\n",
    "            x = self.pool(x)\n",
    "        return block_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the encoder output: torch.Size([1, 64, 568, 568])\n",
      "Shape of the encoder output: torch.Size([1, 128, 280, 280])\n",
      "Shape of the encoder output: torch.Size([1, 256, 136, 136])\n",
      "Shape of the encoder output: torch.Size([1, 512, 64, 64])\n",
      "Shape of the encoder output: torch.Size([1, 1024, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# Check the encoder\n",
    "encoder = Encoder()\n",
    "x = torch.rand(1, 1, 572, 572)\n",
    "encoder_outputs = encoder(x)\n",
    "\n",
    "for op in encoder_outputs:\n",
    "    print(f'Shape of the encoder output: {op.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, channels=(1024, 512, 256, 128, 64)):\n",
    "        super().__init__()\n",
    "        self.channels = channels\n",
    "        self.decoder_blocks = nn.ModuleList(\n",
    "            [Block(channels[i], channels[i + 1]) for i in range(len(channels) - 1)]\n",
    "        )\n",
    "        self.upconvolution = nn.ModuleList(\n",
    "            [nn.ConvTranspose2d(channels[i], channels[i + 1], kernel_size=2, stride=2) for i in range(len(channels) - 1)]\n",
    "        )\n",
    "\n",
    "    def forward(self, x, encoder_outputs):\n",
    "        for i in range(len(self.channels) - 1):\n",
    "            x = self.upconvolution[i](x)\n",
    "            encoder_output = self.crop(encoder_outputs[i], x)\n",
    "            x = torch.cat([x, encoder_output], dim=1)\n",
    "            x = self.decoder_blocks[i](x)\n",
    "        return x\n",
    "\n",
    "    # Following the paper, we crop the encoder output to match the shape of decoder output    \n",
    "    def crop(self, encoder_output, tensor):\n",
    "        _, _, H, W = tensor.shape\n",
    "        encoder_output = torchvision.transforms.CenterCrop([H, W])(encoder_output)\n",
    "        return encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the decoder output: torch.Size([1, 64, 388, 388])\n"
     ]
    }
   ],
   "source": [
    "# Check the decoder\n",
    "decoder = Decoder()\n",
    "x = torch.rand(1, 1024, 28, 28)\n",
    "decoder(x, encoder_outputs[::-1][1:]) # Pass the encoder outputs in reverse order\n",
    "print(f'Shape of the decoder output: {decoder(x, encoder_outputs[::-1][1:]).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, encoder_channels=(1, 64, 128, 256, 512, 1024), decoder_channels=(1024, 512, 256, 128, 64), num_classes=5, retain_dim=False, output_size=(572, 572)):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(encoder_channels)\n",
    "        self.decoder = Decoder(decoder_channels)\n",
    "        self.head = nn.Conv2d(decoder_channels[-1], num_classes, kernel_size=1)\n",
    "        self.retain_dim = retain_dim\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoder_outputs = self.encoder(x)\n",
    "        out = self.decoder(encoder_outputs[-1], encoder_outputs[::-1][1:])\n",
    "        out = self.head(out)\n",
    "        if self.retain_dim:\n",
    "            out = nn.functional.interpolate(out, self.output_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the model output: torch.Size([1, 5, 572, 572])\n"
     ]
    }
   ],
   "source": [
    "# Check the model\n",
    "model = UNet(retain_dim=True)\n",
    "x = torch.rand(1, 1, 572, 572)\n",
    "out = model(x)\n",
    "print(f'Shape of the model output: {out.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "========================================================================================================================\n",
       "Layer (type (var_name))                  Input Shape          Output Shape         Param #              Trainable\n",
       "========================================================================================================================\n",
       "UNet (UNet)                              [1, 1, 572, 572]     [1, 5, 572, 572]     --                   True\n",
       "├─Encoder (encoder)                      [1, 1, 572, 572]     [1, 64, 568, 568]    --                   True\n",
       "│    └─ModuleList (encoder_blocks)       --                   --                   (recursive)          True\n",
       "│    │    └─Block (0)                    [1, 1, 572, 572]     [1, 64, 568, 568]    --                   True\n",
       "│    │    │    └─Conv2d (conv1)          [1, 1, 572, 572]     [1, 64, 570, 570]    640                  True\n",
       "│    │    │    └─ReLU (relu)             [1, 64, 570, 570]    [1, 64, 570, 570]    --                   --\n",
       "│    │    │    └─Conv2d (conv2)          [1, 64, 570, 570]    [1, 64, 568, 568]    36,928               True\n",
       "│    │    │    └─ReLU (relu)             [1, 64, 568, 568]    [1, 64, 568, 568]    --                   --\n",
       "│    └─MaxPool2d (pool)                  [1, 64, 568, 568]    [1, 64, 284, 284]    --                   --\n",
       "│    └─ModuleList (encoder_blocks)       --                   --                   (recursive)          True\n",
       "│    │    └─Block (1)                    [1, 64, 284, 284]    [1, 128, 280, 280]   --                   True\n",
       "│    │    │    └─Conv2d (conv1)          [1, 64, 284, 284]    [1, 128, 282, 282]   73,856               True\n",
       "│    │    │    └─ReLU (relu)             [1, 128, 282, 282]   [1, 128, 282, 282]   --                   --\n",
       "│    │    │    └─Conv2d (conv2)          [1, 128, 282, 282]   [1, 128, 280, 280]   147,584              True\n",
       "│    │    │    └─ReLU (relu)             [1, 128, 280, 280]   [1, 128, 280, 280]   --                   --\n",
       "│    └─MaxPool2d (pool)                  [1, 128, 280, 280]   [1, 128, 140, 140]   --                   --\n",
       "│    └─ModuleList (encoder_blocks)       --                   --                   (recursive)          True\n",
       "│    │    └─Block (2)                    [1, 128, 140, 140]   [1, 256, 136, 136]   --                   True\n",
       "│    │    │    └─Conv2d (conv1)          [1, 128, 140, 140]   [1, 256, 138, 138]   295,168              True\n",
       "│    │    │    └─ReLU (relu)             [1, 256, 138, 138]   [1, 256, 138, 138]   --                   --\n",
       "│    │    │    └─Conv2d (conv2)          [1, 256, 138, 138]   [1, 256, 136, 136]   590,080              True\n",
       "│    │    │    └─ReLU (relu)             [1, 256, 136, 136]   [1, 256, 136, 136]   --                   --\n",
       "│    └─MaxPool2d (pool)                  [1, 256, 136, 136]   [1, 256, 68, 68]     --                   --\n",
       "│    └─ModuleList (encoder_blocks)       --                   --                   (recursive)          True\n",
       "│    │    └─Block (3)                    [1, 256, 68, 68]     [1, 512, 64, 64]     --                   True\n",
       "│    │    │    └─Conv2d (conv1)          [1, 256, 68, 68]     [1, 512, 66, 66]     1,180,160            True\n",
       "│    │    │    └─ReLU (relu)             [1, 512, 66, 66]     [1, 512, 66, 66]     --                   --\n",
       "│    │    │    └─Conv2d (conv2)          [1, 512, 66, 66]     [1, 512, 64, 64]     2,359,808            True\n",
       "│    │    │    └─ReLU (relu)             [1, 512, 64, 64]     [1, 512, 64, 64]     --                   --\n",
       "│    └─MaxPool2d (pool)                  [1, 512, 64, 64]     [1, 512, 32, 32]     --                   --\n",
       "│    └─ModuleList (encoder_blocks)       --                   --                   (recursive)          True\n",
       "│    │    └─Block (4)                    [1, 512, 32, 32]     [1, 1024, 28, 28]    --                   True\n",
       "│    │    │    └─Conv2d (conv1)          [1, 512, 32, 32]     [1, 1024, 30, 30]    4,719,616            True\n",
       "│    │    │    └─ReLU (relu)             [1, 1024, 30, 30]    [1, 1024, 30, 30]    --                   --\n",
       "│    │    │    └─Conv2d (conv2)          [1, 1024, 30, 30]    [1, 1024, 28, 28]    9,438,208            True\n",
       "│    │    │    └─ReLU (relu)             [1, 1024, 28, 28]    [1, 1024, 28, 28]    --                   --\n",
       "│    └─MaxPool2d (pool)                  [1, 1024, 28, 28]    [1, 1024, 14, 14]    --                   --\n",
       "├─Decoder (decoder)                      [1, 1024, 28, 28]    [1, 64, 388, 388]    --                   True\n",
       "│    └─ModuleList (upconvolution)        --                   --                   (recursive)          True\n",
       "│    │    └─ConvTranspose2d (0)          [1, 1024, 28, 28]    [1, 512, 56, 56]     2,097,664            True\n",
       "│    └─ModuleList (decoder_blocks)       --                   --                   (recursive)          True\n",
       "│    │    └─Block (0)                    [1, 1024, 56, 56]    [1, 512, 52, 52]     --                   True\n",
       "│    │    │    └─Conv2d (conv1)          [1, 1024, 56, 56]    [1, 512, 54, 54]     4,719,104            True\n",
       "│    │    │    └─ReLU (relu)             [1, 512, 54, 54]     [1, 512, 54, 54]     --                   --\n",
       "│    │    │    └─Conv2d (conv2)          [1, 512, 54, 54]     [1, 512, 52, 52]     2,359,808            True\n",
       "│    │    │    └─ReLU (relu)             [1, 512, 52, 52]     [1, 512, 52, 52]     --                   --\n",
       "│    └─ModuleList (upconvolution)        --                   --                   (recursive)          True\n",
       "│    │    └─ConvTranspose2d (1)          [1, 512, 52, 52]     [1, 256, 104, 104]   524,544              True\n",
       "│    └─ModuleList (decoder_blocks)       --                   --                   (recursive)          True\n",
       "│    │    └─Block (1)                    [1, 512, 104, 104]   [1, 256, 100, 100]   --                   True\n",
       "│    │    │    └─Conv2d (conv1)          [1, 512, 104, 104]   [1, 256, 102, 102]   1,179,904            True\n",
       "│    │    │    └─ReLU (relu)             [1, 256, 102, 102]   [1, 256, 102, 102]   --                   --\n",
       "│    │    │    └─Conv2d (conv2)          [1, 256, 102, 102]   [1, 256, 100, 100]   590,080              True\n",
       "│    │    │    └─ReLU (relu)             [1, 256, 100, 100]   [1, 256, 100, 100]   --                   --\n",
       "│    └─ModuleList (upconvolution)        --                   --                   (recursive)          True\n",
       "│    │    └─ConvTranspose2d (2)          [1, 256, 100, 100]   [1, 128, 200, 200]   131,200              True\n",
       "│    └─ModuleList (decoder_blocks)       --                   --                   (recursive)          True\n",
       "│    │    └─Block (2)                    [1, 256, 200, 200]   [1, 128, 196, 196]   --                   True\n",
       "│    │    │    └─Conv2d (conv1)          [1, 256, 200, 200]   [1, 128, 198, 198]   295,040              True\n",
       "│    │    │    └─ReLU (relu)             [1, 128, 198, 198]   [1, 128, 198, 198]   --                   --\n",
       "│    │    │    └─Conv2d (conv2)          [1, 128, 198, 198]   [1, 128, 196, 196]   147,584              True\n",
       "│    │    │    └─ReLU (relu)             [1, 128, 196, 196]   [1, 128, 196, 196]   --                   --\n",
       "│    └─ModuleList (upconvolution)        --                   --                   (recursive)          True\n",
       "│    │    └─ConvTranspose2d (3)          [1, 128, 196, 196]   [1, 64, 392, 392]    32,832               True\n",
       "│    └─ModuleList (decoder_blocks)       --                   --                   (recursive)          True\n",
       "│    │    └─Block (3)                    [1, 128, 392, 392]   [1, 64, 388, 388]    --                   True\n",
       "│    │    │    └─Conv2d (conv1)          [1, 128, 392, 392]   [1, 64, 390, 390]    73,792               True\n",
       "│    │    │    └─ReLU (relu)             [1, 64, 390, 390]    [1, 64, 390, 390]    --                   --\n",
       "│    │    │    └─Conv2d (conv2)          [1, 64, 390, 390]    [1, 64, 388, 388]    36,928               True\n",
       "│    │    │    └─ReLU (relu)             [1, 64, 388, 388]    [1, 64, 388, 388]    --                   --\n",
       "├─Conv2d (head)                          [1, 64, 388, 388]    [1, 5, 388, 388]     325                  True\n",
       "========================================================================================================================\n",
       "Total params: 31,030,853\n",
       "Trainable params: 31,030,853\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 167.49\n",
       "========================================================================================================================\n",
       "Input size (MB): 1.31\n",
       "Forward/backward pass size (MB): 1078.44\n",
       "Params size (MB): 124.12\n",
       "Estimated Total Size (MB): 1203.87\n",
       "========================================================================================================================"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "unet_model = UNet(retain_dim=True, num_classes=5, output_size=(572, 572))\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "unet_model = unet_model.to(DEVICE)\n",
    "\n",
    "summary(model=unet_model,\n",
    "        input_size=(1, 1, 572, 572),\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"],\n",
    "        depth=5\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unet_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
